{"cells":[{"cell_type":"markdown","metadata":{"id":"4_bIyq6H_h9G"},"source":["# English-to-German translation with a sequence-to-sequence Transformer\n","\n","\n","**Disclaimer**: This code has been adapted from an original notebook with the following details:\n","\n","**Notebook:** https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb"]},{"cell_type":"markdown","metadata":{"id":"PSQ618ml_h9L"},"source":["## Introduction\n","\n","In this example, we'll build a sequence-to-sequence Transformer model, which\n","we'll train on an English-to-German machine translation task.\n","\n","The code featured here is adapted from the book\n","[Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n","(chapter 11: Deep learning for text).\n","The present example is fairly barebones, so for detailed explanations of\n","how each building block works, as well as the theory behind Transformers,\n","I recommend reading the book."]},{"cell_type":"code","source":["!pip install -q tqdm\n","!pip install -q datasets\n","!pip install -q torchmetrics"],"metadata":{"id":"PTYnTw84RHAR","executionInfo":{"status":"ok","timestamp":1693231947129,"user_tz":-180,"elapsed":13479,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zRxy4MOB_h9L"},"source":["## Setup"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"OQrMlrgD_h9M","executionInfo":{"status":"ok","timestamp":1693231947131,"user_tz":-180,"elapsed":61,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"outputs":[],"source":["import re\n","import random\n","import string\n","import pathlib\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TextVectorization"]},{"cell_type":"code","source":["# for reproducible code\n","import numpy as np\n","import tensorflow as tf\n","import random as python_random\n","\n","seed = 1\n","\n","def reset_seeds():\n","   np.random.seed(seed)\n","   python_random.seed(seed)\n","   tf.random.set_seed(seed)\n","\n","reset_seeds()\n","keras.utils.set_random_seed(seed)\n","tf.config.experimental.enable_op_determinism()"],"metadata":{"id":"TG2jEP8BNBC3","executionInfo":{"status":"ok","timestamp":1693231947132,"user_tz":-180,"elapsed":60,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vQ4nWyvR_h9N"},"source":["## Downloading the data\n","\n","We'll be working with an English-to-German translation dataset called Multi30k (https://arxiv.org/abs/1605.00459)"]},{"cell_type":"markdown","metadata":{"id":"obhj95Bh_h9O"},"source":["## Parsing the data\n","\n","Each line contains an English sentence and its corresponding German sentence.\n","The English sentence is the *source sequence* and German one is the *target sequence*.\n","We prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the German sentence."]},{"cell_type":"code","source":["import datasets\n","\n","dataset = datasets.load_dataset('bentrevett/multi30k')\n","dataset"],"metadata":{"id":"FOkMOyZ_SB4v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693231950814,"user_tz":-180,"elapsed":3741,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"519f478d-9813-4d4e-a115-419845ee9c06"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['en', 'de'],\n","        num_rows: 29000\n","    })\n","    validation: Dataset({\n","        features: ['en', 'de'],\n","        num_rows: 1014\n","    })\n","    test: Dataset({\n","        features: ['en', 'de'],\n","        num_rows: 1000\n","    })\n","})"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","execution_count":26,"metadata":{"id":"S9OdGyBF_h9Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693231950815,"user_tz":-180,"elapsed":49,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"fb117674-9923-4002-ff3f-cb1e0e6c7457"},"outputs":[{"output_type":"stream","name":"stdout","text":["29000 training pairs\n","1014 validation pairs\n","1000 test pairs\n"]}],"source":["train_pairs = list(\n","    [en_document,f'[start] {de_document} [end]']\n","    for en_document,de_document in zip(\n","        dataset['train']['en'],\n","        dataset['train']['de'],\n","      )\n","  )\n","\n","val_pairs = list(\n","    [en_document,f'[start] {de_document} [end]']\n","    for en_document,de_document in zip(\n","        dataset['validation']['en'],\n","        dataset['validation']['de'],\n","      )\n","  )\n","\n","test_pairs = list(\n","    [en_document,f'[start] {de_document} [end]']\n","    for en_document,de_document in zip(\n","        dataset['test']['en'],\n","        dataset['test']['de'],\n","      )\n","  )\n","\n","print(f\"{len(train_pairs)} training pairs\")\n","print(f\"{len(val_pairs)} validation pairs\")\n","print(f\"{len(test_pairs)} test pairs\")"]},{"cell_type":"markdown","metadata":{"id":"2FLOWJh8_h9Q"},"source":["## Vectorizing the text data\n","\n","We'll use two instances of the `TextVectorization` layer to vectorize the text\n","data (one for English and one for German),\n","that is to say, to turn the original strings into integer sequences\n","where each integer represents the index of a word in a vocabulary.\n","\n","Both layers will use the default string standardization (strip punctuation characters)\n","and splitting scheme (split on whitespace)"]},{"cell_type":"code","source":["from collections import defaultdict"],"metadata":{"id":"jxBDHuVkJTSR","executionInfo":{"status":"ok","timestamp":1693231950816,"user_tz":-180,"elapsed":44,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# calculate vocab sizes\n","en_vocab = defaultdict(int)\n","de_vocab = defaultdict(int)\n","\n","for (en_item,de_item) in train_pairs:\n","  for token in en_item.split():\n","    en_vocab[token] += 1\n","  for token in de_item.split():\n","    de_vocab[token] += 1\n","\n","en_vocab = dict(en_vocab)\n","de_vocab = dict(de_vocab)\n","\n","len(en_vocab),len(de_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qzrtd966I1sw","executionInfo":{"status":"ok","timestamp":1693231952803,"user_tz":-180,"elapsed":2030,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"bb4ce754-d69c-4b49-9767-d4e4b3d31c25"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15456, 24891)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["de_vocab = {vocab:freq for vocab,freq in de_vocab.items() if freq > 1}\n","len(de_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nwjae4QzD7Ls","executionInfo":{"status":"ok","timestamp":1693231952804,"user_tz":-180,"elapsed":25,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"d1754b13-1184-476c-db00-141e3a1571ca"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9760"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","execution_count":30,"metadata":{"id":"4HRncM1e_h9Q","executionInfo":{"status":"ok","timestamp":1693231955904,"user_tz":-180,"elapsed":3120,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"outputs":[],"source":["strip_chars = string.punctuation\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\")\n","\n","sequence_length = 35\n","batch_size = 64\n","\n","\n","def custom_standardization(input_string):\n","    lowercase = tf.strings.lower(input_string)\n","    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n","\n","\n","eng_vectorization = TextVectorization(\n","    max_tokens=len(en_vocab),\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length,\n",")\n","de_vectorization = TextVectorization(\n","    max_tokens=len(de_vocab),\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=custom_standardization,\n",")\n","train_eng_texts = [pair[0] for pair in train_pairs]\n","train_de_texts = [pair[1] for pair in train_pairs]\n","eng_vectorization.adapt(train_eng_texts)\n","de_vectorization.adapt(train_de_texts)"]},{"cell_type":"code","source":["input_vocab_size = len(eng_vectorization.get_vocabulary())\n","output_vocab_size = len(de_vectorization.get_vocabulary())\n","# numbers here might be different than above because of the transformations applied\n","input_vocab_size,output_vocab_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAmW0oLi6Big","executionInfo":{"status":"ok","timestamp":1693231955905,"user_tz":-180,"elapsed":14,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"210e1b21-5b5f-4a00-80c2-9f1335056b22"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10203, 9760)"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"fU0RQZg0_h9R"},"source":["Next, we'll format our datasets.\n","\n","At each training step, the model will seek to predict target words N+1 (and beyond)\n","using the source sentence and the target words 0 to N.\n","\n","As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n","\n","- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n","`encoder_inputs` is the vectorized source sentence and `encoder_inputs` is the target sentence \"so far\",\n","that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n","- `target` is the target sentence offset by one step:\n","it provides the next words in the target sentence -- what the model will try to predict."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"eTfCVLCS_h9R","executionInfo":{"status":"ok","timestamp":1693231957753,"user_tz":-180,"elapsed":1859,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"outputs":[],"source":["def format_dataset(eng, de):\n","    eng = eng_vectorization(eng)\n","    de = de_vectorization(de)\n","    return (\n","        {\n","            \"encoder_inputs\": eng,\n","            \"decoder_inputs\": de[:, :-1],\n","        },\n","        de[:, 1:],\n","    )\n","\n","\n","def make_dataset(pairs):\n","    eng_texts, de_texts = zip(*pairs)\n","    eng_texts = list(eng_texts)\n","    de_texts = list(de_texts)\n","    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, de_texts))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset)\n","    return dataset.shuffle(2048).prefetch(16).cache()\n","\n","\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)\n","test_ds = make_dataset(test_pairs)"]},{"cell_type":"markdown","metadata":{"id":"u_ejNv4s_h9R"},"source":["Let's take a quick look at the sequence shapes\n","(we have batches of 64 pairs, and all sequences are 20 steps long):"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"qgAKAkyx_h9R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693231957754,"user_tz":-180,"elapsed":11,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"f6857bb3-e99c-46d8-ad26-fdbfce352b62"},"outputs":[{"output_type":"stream","name":"stdout","text":["inputs[\"encoder_inputs\"].shape: (64, 35)\n","inputs[\"decoder_inputs\"].shape: (64, 35)\n","targets.shape: (64, 35)\n"]}],"source":["for inputs, targets in train_ds.take(1):\n","  print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","  print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","  print(f\"targets.shape: {targets.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"Go6Bdmev_h9S"},"source":["## Building the model\n","\n","Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n","and a `TransformerDecoder` chained together. To make the model aware of word order,\n","we also use a `PositionalEmbedding` layer.\n","\n","The source sequence will be pass to the `TransformerEncoder`,\n","which will produce a new representation of it.\n","This new representation will then be passed\n","to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n","The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n","\n","A key detail that makes this possible is causal masking\n","(`use_causal_mask=True` in the first attention layer of the `TransformerDecoder`).\n","The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n","sure that it only uses information from target tokens 0 to N when predicting token N+1\n","(otherwise, it could use information from the future, which would\n","result in a model that cannot be used at inference time)."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"mxBLT60T_h9S","executionInfo":{"status":"ok","timestamp":1693231957754,"user_tz":-180,"elapsed":9,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"outputs":[],"source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(dense_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        attention_output = self.attention(query=inputs, value=inputs, key=inputs)\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"embed_dim\": self.embed_dim,\n","                \"dense_dim\": self.dense_dim,\n","                \"num_heads\": self.num_heads,\n","            }\n","        )\n","        return config\n","\n","\n","class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=vocab_size, output_dim=embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=embed_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"sequence_length\": self.sequence_length,\n","                \"vocab_size\": self.vocab_size,\n","                \"embed_dim\": self.embed_dim,\n","            }\n","        )\n","        return config\n","\n","\n","class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(latent_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.add = layers.Add()  # instead of `+` to preserve mask\n","        self.supports_masking = True\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        attention_output_1 = self.attention_1(\n","            query=inputs, value=inputs, key=inputs, use_causal_mask=True\n","        )\n","        out_1 = self.layernorm_1(self.add([inputs, attention_output_1]))\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","        )\n","        out_2 = self.layernorm_2(self.add([out_1, attention_output_2]))\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(self.add([out_2, proj_output]))\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"embed_dim\": self.embed_dim,\n","                \"latent_dim\": self.latent_dim,\n","                \"num_heads\": self.num_heads,\n","            }\n","        )\n","        return config\n"]},{"cell_type":"markdown","metadata":{"id":"QrV3en83_h9T"},"source":["Next, we assemble the end-to-end model."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"0kYpXffU_h9T","executionInfo":{"status":"ok","timestamp":1693231958872,"user_tz":-180,"elapsed":1126,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"outputs":[],"source":["embed_dim = 256\n","latent_dim = 2048\n","num_heads = 8\n","\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(sequence_length, input_vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(sequence_length, output_vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(output_vocab_size, activation=\"softmax\")(x)\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","transformer = keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"uut87tWn_h9T"},"source":["## Training our model\n","\n","We'll use accuracy as a quick way to monitor training progress on the validation data.\n","Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n","\n","Here, we are training the model for 10 epochs"]},{"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint"],"metadata":{"id":"Oovm5XNxGJGM","executionInfo":{"status":"ok","timestamp":1693231958873,"user_tz":-180,"elapsed":51,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","execution_count":37,"metadata":{"id":"LKJxKw00_h9T","outputId":"1e144201-aeab-41d0-eadf-1fb72749b1a5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693232674209,"user_tz":-180,"elapsed":715387,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," positional_embedding_2 (Positi  (None, None, 256)   2620928     ['encoder_inputs[0][0]']         \n"," onalEmbedding)                                                                                   \n","                                                                                                  \n"," decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," transformer_encoder_1 (Transfo  (None, None, 256)   3155456     ['positional_embedding_2[0][0]'] \n"," rmerEncoder)                                                                                     \n","                                                                                                  \n"," model_3 (Functional)           (None, None, 9760)   10275360    ['decoder_inputs[0][0]',         \n","                                                                  'transformer_encoder_1[0][0]']  \n","                                                                                                  \n","==================================================================================================\n","Total params: 16,051,744\n","Trainable params: 16,051,744\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/10\n","454/454 [==============================] - ETA: 0s - loss: 4.0907 - accuracy: 0.3606\n","Epoch 1: val_loss improved from inf to 3.05247, saving model to model-001-4.090738-3.052473.h5\n","454/454 [==============================] - 105s 203ms/step - loss: 4.0907 - accuracy: 0.3606 - val_loss: 3.0525 - val_accuracy: 0.4772\n","Epoch 2/10\n","454/454 [==============================] - ETA: 0s - loss: 2.9003 - accuracy: 0.5177\n","Epoch 2: val_loss improved from 3.05247 to 2.43586, saving model to model-002-2.900270-2.435862.h5\n","454/454 [==============================] - 56s 124ms/step - loss: 2.9003 - accuracy: 0.5177 - val_loss: 2.4359 - val_accuracy: 0.5667\n","Epoch 3/10\n","454/454 [==============================] - ETA: 0s - loss: 2.4558 - accuracy: 0.5758\n","Epoch 3: val_loss improved from 2.43586 to 2.20572, saving model to model-003-2.455765-2.205723.h5\n","454/454 [==============================] - 56s 124ms/step - loss: 2.4558 - accuracy: 0.5758 - val_loss: 2.2057 - val_accuracy: 0.5970\n","Epoch 4/10\n","454/454 [==============================] - ETA: 0s - loss: 2.1922 - accuracy: 0.6100\n","Epoch 4: val_loss improved from 2.20572 to 2.14552, saving model to model-004-2.192216-2.145515.h5\n","454/454 [==============================] - 57s 125ms/step - loss: 2.1922 - accuracy: 0.6100 - val_loss: 2.1455 - val_accuracy: 0.5977\n","Epoch 5/10\n","454/454 [==============================] - ETA: 0s - loss: 1.9996 - accuracy: 0.6358\n","Epoch 5: val_loss improved from 2.14552 to 2.03213, saving model to model-005-1.999650-2.032128.h5\n","454/454 [==============================] - 57s 125ms/step - loss: 1.9996 - accuracy: 0.6358 - val_loss: 2.0321 - val_accuracy: 0.6233\n","Epoch 6/10\n","454/454 [==============================] - ETA: 0s - loss: 1.8468 - accuracy: 0.6564\n","Epoch 6: val_loss did not improve from 2.03213\n","454/454 [==============================] - 57s 125ms/step - loss: 1.8468 - accuracy: 0.6564 - val_loss: 2.0374 - val_accuracy: 0.6248\n","Epoch 7/10\n","454/454 [==============================] - ETA: 0s - loss: 1.7187 - accuracy: 0.6759\n","Epoch 7: val_loss improved from 2.03213 to 2.00387, saving model to model-007-1.718665-2.003866.h5\n","454/454 [==============================] - 56s 124ms/step - loss: 1.7187 - accuracy: 0.6759 - val_loss: 2.0039 - val_accuracy: 0.6298\n","Epoch 8/10\n","454/454 [==============================] - ETA: 0s - loss: 1.6079 - accuracy: 0.6919\n","Epoch 8: val_loss did not improve from 2.00387\n","454/454 [==============================] - 56s 124ms/step - loss: 1.6079 - accuracy: 0.6919 - val_loss: 2.0804 - val_accuracy: 0.6265\n","Epoch 9/10\n","454/454 [==============================] - ETA: 0s - loss: 1.5109 - accuracy: 0.7078\n","Epoch 9: val_loss did not improve from 2.00387\n","454/454 [==============================] - 56s 124ms/step - loss: 1.5109 - accuracy: 0.7078 - val_loss: 2.0994 - val_accuracy: 0.6231\n","Epoch 10/10\n","454/454 [==============================] - ETA: 0s - loss: 1.4256 - accuracy: 0.7219\n","Epoch 10: val_loss did not improve from 2.00387\n","454/454 [==============================] - 57s 125ms/step - loss: 1.4256 - accuracy: 0.7219 - val_loss: 2.1127 - val_accuracy: 0.6335\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7a4f0eed9300>"]},"metadata":{},"execution_count":37}],"source":["epochs = 10\n","\n","transformer.summary()\n","transformer.compile(\n","    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")\n","checkpointing_callback = ModelCheckpoint('model-{epoch:03d}-{loss:03f}-{val_loss:03f}.h5',\n","    verbose=1,\n","    monitor='val_loss',\n","    save_best_only=True,\n","    mode='auto'\n",")\n","transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[checkpointing_callback])"]},{"cell_type":"markdown","metadata":{"id":"VBWfRt_-_h9T"},"source":["## Decoding test sentences\n","\n","Finally, let's demonstrate how to translate brand new English sentences.\n","We simply feed into the model the vectorized English sentence\n","as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n","we hit the token `\"[end]\"`."]},{"cell_type":"code","execution_count":43,"metadata":{"id":"0bux4DAw_h9T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693232869518,"user_tz":-180,"elapsed":3514,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"8d5b27c6-459c-41e7-b46a-376c5cf84a12"},"outputs":[{"output_type":"stream","name":"stdout","text":["################################################################################\n","A young woman with a black shirt and jeans sweeping.\n","[start] eine junge frau in einem schwarzen hemd und jeans kehrt den jeans [end]\n","################################################################################\n","################################################################################\n","On stage photo of small band performing for theater audience.\n","[start] ein foto von einer kleinen [UNK] für die bühne auf der bühne auf der bühne [end]\n","################################################################################\n","################################################################################\n","Two people are silhouetted against a lake reflecting a painted sky.\n","[start] zwei personen lehnt sich an einem see und einem [UNK] ab [end]\n","################################################################################\n"]}],"source":["de_vocab = de_vectorization.get_vocabulary()\n","de_index_lookup = dict(zip(range(len(de_vocab)), de_vocab))\n","max_decoded_sentence_length = sequence_length\n","\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = eng_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = de_vectorization([decoded_sentence])[:, :-1]\n","        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n","\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = de_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence\n","\n","\n","test_eng_texts = [pair[0] for pair in test_pairs]\n","test_de_texts = [pair[1] for pair in test_pairs]\n","for _ in range(3):\n","    input_sentence = random.choice(test_eng_texts)\n","    translated = decode_sequence(input_sentence)\n","    print('#'*80)\n","    print(input_sentence)\n","    print(translated)\n","    print('#'*80)"]},{"cell_type":"markdown","source":["## Calculate BLUE score"],"metadata":{"id":"H1bmc8EyT7gv"}},{"cell_type":"code","source":["from torchmetrics.text import BLEUScore\n","from tqdm.auto import tqdm"],"metadata":{"id":"RQ9_ht4EaKkh","executionInfo":{"status":"ok","timestamp":1693232869520,"user_tz":-180,"elapsed":33,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["target = [[sentence.lower()] for sentence in tqdm(test_de_texts)]\n","preds = [decode_sequence(custom_standardization(sentence)) for sentence in tqdm(test_eng_texts)]"],"metadata":{"id":"ft_TZCcGT_NE","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["df8b5e2e2f664d2ca0989274213d1809","aac6d8679f254827b8d6d9f2cbfebe46","c8ef1871cbb5468990d9dbf21dd90d55","27d350cf92b3434ba1aef2323b552ec7","41bf405b8a694b73aab43cff14391db3","fcddb532336e482db7a5f3702da3c3b5","98fdb9a5fb0a46e88b992eca816543a4","36cc1bc8a4f24972abb98044fced2832","8e2f3ceac66840f38f982d5fadbc0da2","32328f6568b74428860cf2428a631b7e","af98563897444f55b3fa9413e5a849cb","8d7c07e154da485499dc74f42bfcaeac","298466e787174e5c939fe01b9fcb6241","2a4b394f4ccd42f49d82b29ddc64db1f","79fe0c1a4c1b4fdf9c65d4175bb29012","d7e1e104439f417fbc1dc03e025fe980","5822a118498c426eb526df407faa790c","223bfecb41f3428ab4de83b6165e9dc4","208730f467284866b3449e5cdd8528cf","d18f566617a74dc0a5f9f0b40854bd2f","c14d89de5ef44a9181c8cab5b2ea1529","b9eb43982ce3452994678ce29f5e13d8"]},"executionInfo":{"status":"ok","timestamp":1693233524620,"user_tz":-180,"elapsed":350966,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"baf853d2-92de-4054-9713-8548b908cc11"},"execution_count":45,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df8b5e2e2f664d2ca0989274213d1809","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d7c07e154da485499dc74f42bfcaeac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","source":["# show some examples by index\n","index = 9\n","test_eng_texts[index],preds[index],target[index]"],"metadata":{"id":"_f4ojK7hilSx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693233524622,"user_tz":-180,"elapsed":6,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"b10640ae-dafd-4963-9a8c-992a53d6c02d"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('A man in a vest is sitting in a chair and holding magazines.',\n"," '[start] ein mann in einer weste sitzt in einem stuhl und hält ein [UNK] [end]',\n"," ['[start] ein mann in einer weste sitzt auf einem stuhl und hält magazine. [end]'])"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["bleu = BLEUScore(n_gram=4)\n","bleu(preds, target)"],"metadata":{"id":"YFKTq2WTazfi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693233526401,"user_tz":-180,"elapsed":1782,"user":{"displayName":"Maged Saeed","userId":"08011552846066909361"}},"outputId":"48819137-452a-4134-93a9-674effe863cd"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.3056)"]},"metadata":{},"execution_count":47}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb","timestamp":1693077040046}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"df8b5e2e2f664d2ca0989274213d1809":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aac6d8679f254827b8d6d9f2cbfebe46","IPY_MODEL_c8ef1871cbb5468990d9dbf21dd90d55","IPY_MODEL_27d350cf92b3434ba1aef2323b552ec7"],"layout":"IPY_MODEL_41bf405b8a694b73aab43cff14391db3"}},"aac6d8679f254827b8d6d9f2cbfebe46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcddb532336e482db7a5f3702da3c3b5","placeholder":"​","style":"IPY_MODEL_98fdb9a5fb0a46e88b992eca816543a4","value":"100%"}},"c8ef1871cbb5468990d9dbf21dd90d55":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36cc1bc8a4f24972abb98044fced2832","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e2f3ceac66840f38f982d5fadbc0da2","value":1000}},"27d350cf92b3434ba1aef2323b552ec7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32328f6568b74428860cf2428a631b7e","placeholder":"​","style":"IPY_MODEL_af98563897444f55b3fa9413e5a849cb","value":" 1000/1000 [00:00&lt;00:00, 46163.80it/s]"}},"41bf405b8a694b73aab43cff14391db3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcddb532336e482db7a5f3702da3c3b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98fdb9a5fb0a46e88b992eca816543a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36cc1bc8a4f24972abb98044fced2832":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e2f3ceac66840f38f982d5fadbc0da2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32328f6568b74428860cf2428a631b7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af98563897444f55b3fa9413e5a849cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d7c07e154da485499dc74f42bfcaeac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_298466e787174e5c939fe01b9fcb6241","IPY_MODEL_2a4b394f4ccd42f49d82b29ddc64db1f","IPY_MODEL_79fe0c1a4c1b4fdf9c65d4175bb29012"],"layout":"IPY_MODEL_d7e1e104439f417fbc1dc03e025fe980"}},"298466e787174e5c939fe01b9fcb6241":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5822a118498c426eb526df407faa790c","placeholder":"​","style":"IPY_MODEL_223bfecb41f3428ab4de83b6165e9dc4","value":"100%"}},"2a4b394f4ccd42f49d82b29ddc64db1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_208730f467284866b3449e5cdd8528cf","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d18f566617a74dc0a5f9f0b40854bd2f","value":1000}},"79fe0c1a4c1b4fdf9c65d4175bb29012":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c14d89de5ef44a9181c8cab5b2ea1529","placeholder":"​","style":"IPY_MODEL_b9eb43982ce3452994678ce29f5e13d8","value":" 1000/1000 [10:55&lt;00:00,  1.54it/s]"}},"d7e1e104439f417fbc1dc03e025fe980":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5822a118498c426eb526df407faa790c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"223bfecb41f3428ab4de83b6165e9dc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"208730f467284866b3449e5cdd8528cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d18f566617a74dc0a5f9f0b40854bd2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c14d89de5ef44a9181c8cab5b2ea1529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9eb43982ce3452994678ce29f5e13d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}